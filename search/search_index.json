{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"workshop-azure-openai","text":"<p>This repository is for a workshop using Azure OpenAI Service.</p>"},{"location":"#prerequisites","title":"Prerequisites","text":"<p>To run all the projects in this repository, you need the followings.</p> <ul> <li>Python 3.10+</li> <li>Azure OpenAI Service</li> <li>Azure Cosmos DB</li> <li>Azure AI Search</li> <li>Azure AI Document Intelligence</li> </ul> <p>Here are the preferred tools for development.</p> <ul> <li>uv</li> <li>GNU Make</li> </ul>"},{"location":"#setup","title":"Setup","text":""},{"location":"#infrastructure","title":"Infrastructure","text":"<p>Click the button below to deploy the infrastructure to Azure.</p> <p></p>"},{"location":"#projects","title":"Projects","text":"Project Description Image 1_call_azure_openai_chat Call Azure OpenAI Service API from Python No Image 2_streamlit_chat Create an Azure OpenAI Chat app using Streamlit 3_call_azure_cosmos_db Call Azure Cosmos DB from Python No Image 4_streamlit_chat_history Add feature to store chat history using Azure Cosmos DB 5_streamlit_query_chat_history Search Chat History 6_call_azure_ai_search Call Azure AI Search from Python No Image 7_streamlit_chat_rag Add RAG feature to Streamlit chat app 8_streamlit_azure_openai_batch Call Azure OpenAI Batch API with Streamlit 9_streamlit_azure_document_intelligence Call Azure AI Document Intelligence API with Streamlit 10_streamlit_batch_transcription Call Batch Transcription API with Streamlit 11_promptflow Get started with Prompt flow No Image 12_langgraph_agent Create agents with LangGraph No Image 99_streamlit_examples Code samples for Streamlit"},{"location":"#how-to-run","title":"How to run","text":"<p>Referring to the .env.template file, create a <code>.env</code> file in the same directory and set the required credentials.</p>"},{"location":"#local-environment","title":"Local environment","text":"<pre><code># Create a virtual environment\n$ python -m venv .venv\n\n# Activate the virtual environment\n$ source .venv/bin/activate\n\n# Install dependencies\n$ pip install -r requirements.txt\n\n# Run the script (e.g. run 2_streamlit_chat)\n$ python -m streamlit run apps/2_streamlit_chat/main.py\n</code></pre>"},{"location":"#docker-container","title":"Docker container","text":"<pre><code># Set Docker image name\n## GitHub Container Registry\n$ IMAGE=ghcr.io/ks6088ts-labs/workshop-azure-openai:latest\n## Docker Hub\n$ IMAGE=ks6088ts/workshop-azure-openai:latest\n\n# run 2_streamlit_chat\n$ docker run --rm \\\n    -p 8501:8501 \\\n    -v ${PWD}/.env:/app/.env \\\n    ${IMAGE} \\\n    python -m streamlit run /apps/2_streamlit_chat/main.py\n</code></pre>"},{"location":"README.dev/","title":"Developer Guide","text":""},{"location":"README.dev/#development-instructions","title":"Development instructions","text":""},{"location":"README.dev/#local-development","title":"Local development","text":"<p>Use Makefile to run the project locally.</p> <pre><code># help\nmake\n\n# install dependencies for development\nmake install-deps-dev\n\n# run tests\nmake test\n\n# run CI tests\nmake ci-test\n</code></pre>"},{"location":"README.dev/#docker-development","title":"Docker development","text":"<pre><code># build docker image\nmake docker-build\n\n# run docker container\nmake docker-run\n\n# run CI tests in docker container\nmake ci-test-docker\n</code></pre>"},{"location":"README.dev/#deployment","title":"Deployment","text":""},{"location":"README.dev/#infrastructure","title":"Infrastructure","text":"<pre><code>cd infra\naz login\n\nmake deploy\n</code></pre> <ul> <li>ref. Azure-Samples/azure-ai-studio-secure-bicep</li> </ul>"},{"location":"README.dev/#application","title":"Application","text":""},{"location":"README.dev/#from-docker-hub","title":"From Docker Hub","text":"<p>You can run the docker image from Docker Hub.</p> <pre><code># Run 2_streamlit_chat\ndocker run -p 8501:8501 ks6088ts/workshop-azure-openai:latest \\\n    python -m streamlit run apps/2_streamlit_chat/main.py\n\n# Run 99_streamlit_llm_examples\ndocker run -p 8501:8501 ks6088ts/workshop-azure-openai:latest \\\n    python -m streamlit run apps/99_streamlit_llm_examples/main.py\n</code></pre>"},{"location":"README.dev/#app-service","title":"App Service","text":"<p>For deploying the Streamlit application to Azure App Service, you need to set the following two configurations.</p> <ol> <li>Go to <code>Settings &gt; Configuration &gt; Startup Command</code> and set startup command as <code>python -m streamlit run apps/4_streamlit_chat_history/main.py --server.port 8000 --server.address 0.0.0.0</code></li> <li>Set <code>SCM_DO_BUILD_DURING_DEPLOYMENT</code> to <code>true</code></li> </ol> <p>Notes:</p> <ul> <li>Update the startup command as needed. App Service listens on port 8000 by default, so <code>--server.port 8000</code> is required.</li> <li>The default port of App Service is 8000, so <code>--server.port 8000</code> is required.</li> </ul>"},{"location":"README.dev/#references","title":"References","text":"<ul> <li>Streamlit \u3092 Azure App Service \u3067\u52d5\u304b\u3059\uff01</li> <li>WARNING: Could not find virtual environment directory /home/site/wwwroot/antenv</li> <li>How to deploy a streamlit application on Azure App Service (WebApp)</li> </ul>"},{"location":"README.dev/#github-actions","title":"GitHub Actions","text":"<p>To publish the docker image to Docker Hub, you need to set the following secrets in the repository settings.</p> <pre><code>gh secret set DOCKERHUB_USERNAME --body $DOCKERHUB_USERNAME\ngh secret set DOCKERHUB_TOKEN --body $DOCKERHUB_TOKEN\n</code></pre>"},{"location":"apps/10_streamlit_batch_transcription/","title":"10. Call Batch Transcription API with Streamlit","text":"<p>This is a Streamlit app that calls Azure AI Speech Batch Transcription API.</p>"},{"location":"apps/10_streamlit_batch_transcription/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.10 or later</li> <li>Azure AI Speech Service subscription key</li> </ul>"},{"location":"apps/10_streamlit_batch_transcription/#infrastructure-setup","title":"Infrastructure setup","text":"<p>Follow the steps in Assign a resource access role to assign the Storage Blob Data Reader role to the managed identity of your Speech resource.</p> <p>FIXME: automate this step</p>"},{"location":"apps/10_streamlit_batch_transcription/#usage","title":"Usage","text":"<ol> <li>Get Azure AI Speech Service subscription key</li> <li>Copy .env.template to <code>.env</code> in the same directory</li> <li>Set credentials in <code>.env</code></li> <li>Run main.py</li> </ol> <pre><code># Create a virtual environment\n$ python -m venv .venv\n\n# Activate the virtual environment\n$ source .venv/bin/activate\n\n# Install dependencies\n$ pip install -r requirements.txt\n\n# Run the script\n$ python -m streamlit run apps/10_streamlit_batch_transcription/main.py\n</code></pre>"},{"location":"apps/10_streamlit_batch_transcription/#example","title":"Example","text":""},{"location":"apps/10_streamlit_batch_transcription/#references","title":"References","text":"<ul> <li>What is batch transcription?</li> </ul>"},{"location":"apps/11_promptflow/","title":"11. Getting Started with Prompt flow","text":"<p>This application explains how to get started with Prompt flow, a Python library that provides a simple and easy way to build conversational AI applications.</p>"},{"location":"apps/11_promptflow/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.10 or later</li> <li>Azure OpenAI Service</li> </ul>"},{"location":"apps/11_promptflow/#overview","title":"Overview","text":"<p>Prompt flow is a suite of development tools designed to streamline the end-to-end development cycle of LLM-based AI applications, from ideation, prototyping, testing, evaluation to production deployment and monitoring. It makes prompt engineering much easier and enables you to build LLM apps with production quality.</p>"},{"location":"apps/11_promptflow/#usage","title":"Usage","text":"<ol> <li>Get the API key for Azure OpenAI Service</li> <li>Copy .env.template to <code>.env</code> in the same directory</li> <li>Set credentials in <code>.env</code></li> <li>Run scripts in the apps/11_promptflow directory</li> </ol> <p>Set up the environment and install dependencies:</p> <pre><code># Create a virtual environment\n$ python -m venv .venv\n\n# Activate the virtual environment\n$ source .venv/bin/activate\n\n# Install dependencies\n$ pip install -r requirements.txt\n</code></pre>"},{"location":"apps/11_promptflow/#examples","title":"Examples","text":"<p>Prompt flow &gt; Quick start provides a quick start guide to Prompt flow. Some of the examples are extracted from github.com/microsoft/promptflow/examples to guide you through the basic usage of Prompt flow.</p> <p>Set up connection</p> <pre><code>$ cd apps/11_promptflow\n\n# List connections\n$ pf connection list\n\n# Set parameters\n$ AZURE_OPENAI_KEY=&lt;your_api_key&gt;\n$ AZURE_OPENAI_ENDPOINT=&lt;your_api_endpoint&gt;\n$ CONNECTION_NAME=open_ai_connection\n\n# Delete connection (if needed)\n$ pf connection delete \\\n    --name $CONNECTION_NAME\n\n# Create connection\n$ pf connection create \\\n    --file connection_azure_openai.yaml \\\n    --set api_key=$AZURE_OPENAI_KEY \\\n    --set api_base=$AZURE_OPENAI_ENDPOINT \\\n    --name $CONNECTION_NAME\n\n# Show connection\n$ pf connection show \\\n    --name $CONNECTION_NAME\n</code></pre>"},{"location":"apps/11_promptflow/#chat_minimal","title":"chat_minimal","text":"<p>A chat flow defined using function with minimal code. It demonstrates the minimal code to have a chat flow.</p> <p>Tracing feature is available in Prompt flow, which allows you to trace the flow of the conversation. You can see its implementation in this example. Details are available in Tracing</p> <p>Run as normal Python script</p> <pre><code>$ python apps/11_promptflow/chat_minimal/main.py\n</code></pre> <p>Run from CLI</p> <pre><code>$ cd apps/11_promptflow/chat_minimal\n\n# Test flow\n$ pf flow test \\\n    --flow main:chat \\\n    --inputs question=\"What's the capital of France?\"\n\n# Test flow: multi turn, access to http://localhost:{EPHEMERAL_PORT}\n$ pf flow test \\\n    --flow main:chat \\\n    --ui\n\n# Create run with multiple lines data\n$ pf run create \\\n    --flow main:chat \\\n    --data ./data.jsonl \\\n    --column-mapping question='${data.question}' \\\n    --stream\n</code></pre> <p><code>--column-mapping</code> is used to map the data in the JSONL file to the flow. For more details, refer to Use column mapping.</p>"},{"location":"apps/11_promptflow/#playground_chat","title":"playground_chat","text":"<pre><code>cd apps/11_promptflow\n\n# Initialize a new flow\n$ pf flow init \\\n    --flow playground_chat \\\n    --type chat\n\n$ cd playground_chat\n\n# Interact with chat flow\n$ pf flow test \\\n    --flow . \\\n    --interactive\n\n# Test flow\n$ pf flow test \\\n    --flow . \\\n    --inputs question=\"What's the capital of France?\"\n\n# Create run with multiple lines data\n$ RUN_NAME=playground_chat-$(date +%s)\n$ pf run create \\\n    --name $RUN_NAME \\\n    --flow . \\\n    --data ./data.jsonl \\\n    --column-mapping question='${data.question}' \\\n    --stream\n\n# Show run details\n$ pf run show-details --name $RUN_NAME\n</code></pre>"},{"location":"apps/11_promptflow/#playground_evaluation","title":"playground_evaluation","text":"<pre><code>cd apps/11_promptflow\n\n# Initialize a new flow\n$ pf flow init \\\n    --flow playground_evaluation \\\n    --type evaluation\n\n$ cd playground_evaluation\n\n# Create run with multiple lines data\n$ RUN_NAME=playground_evaluation-$(date +%s)\n$ pf run create \\\n    --name $RUN_NAME \\\n    --flow . \\\n    --data ./data.jsonl \\\n    --column-mapping \\\n        groundtruth='${data.groundtruth}' \\\n        prediction='${data.prediction}' \\\n    --stream\n\n# Show run details\n$ pf run show-details --name $RUN_NAME\n</code></pre>"},{"location":"apps/11_promptflow/#playground_standard","title":"playground_standard","text":"<pre><code>cd apps/11_promptflow\n\n# Initialize a new flow\n$ pf flow init \\\n    --flow playground_standard \\\n    --type standard\n\n$ cd playground_standard\n\n# Create run with multiple lines data\n$ RUN_NAME=playground_standard-$(date +%s)\n$ pf run create \\\n    --name $RUN_NAME \\\n    --flow . \\\n    --data ./data.jsonl \\\n    --column-mapping text='${data.text}' \\\n    --stream\n\n# Show run details\n$ pf run show-details --name $RUN_NAME\n</code></pre>"},{"location":"apps/11_promptflow/#image_qa","title":"image_qa","text":"<p>To run the image QA flow with GPT-4o, we customize an LLM tool. Following documents provide more details:</p> <ul> <li>docs: Customizing an LLM Tool</li> <li>example codes: promptflow/examples/flows/chat/chat-with-image</li> </ul> <p>With the image QA flow sample, you can ask questions about an image and get answers from the model.</p> <pre><code>cd apps/11_promptflow/image_qa\n\n# Create run with multiple lines data\n$ RUN_NAME=image_qa-$(date +%s)\n$ pf run create \\\n    --name $RUN_NAME \\\n    --flow . \\\n    --data ./data.jsonl \\\n    --column-mapping image='${data.image}' \\\n    --stream\n\n# Show run details\n$ pf run show-details --name $RUN_NAME\n</code></pre>"},{"location":"apps/11_promptflow/#chat-math-variant","title":"chat-math-variant","text":"<p>Tuning prompts using <code>variants</code> is a powerful feature in Prompt flow. It allows you to test different prompts and see which one works best for your use case.</p> <p>Prompt flow repository provides an example of a chat flow with math variants at examples/flows/chat/chat-math-variant.</p> <p>To understand how to use variants, you can refer to the How-to Guides &gt; Tune prompts using variants document.</p> <pre><code>cd apps/11_promptflow/chat-math-variant\n\n# Create run with multiple lines data with variant\n$ RUN_NAME=chat-math-variant-$(date +%s)\n$ VARIANT='${chat.variant_0}'\n$ pf run create \\\n    --name $RUN_NAME \\\n    --flow . \\\n    --data ./data.jsonl \\\n    --column-mapping question='${data.question}' \\\n    --variant $VARIANT \\\n    --stream\n\n# Show run details\n$ pf run show-details --name $RUN_NAME\n</code></pre> <p>Tutorial: How prompt flow helps on quality improvement provides a detailed guide on how to use Prompt flow to improve the quality of your LLM applications.</p>"},{"location":"apps/11_promptflow/#eval-chat-math","title":"eval-chat-math","text":"<p>This example shows how to evaluate the answer of math questions, which can compare the output results with the standard answers numerically. Details are available in the eval-chat-math/README.md. To understand how to operate the flow in VS Code, you can refer to the Build your high quality LLM apps with Prompt flow. This video shows how to evaluate the answer of math questions and guide you to tune the prompts using variants.</p>"},{"location":"apps/11_promptflow/#flex_flow_langchain","title":"flex_flow_langchain","text":"<p>To guide you through working with LangChain, we provide an example flex flow that</p> <pre><code>$ cd apps/11_promptflow/flex_flow_langchain\n$ pf flow test \\\n    --flow main:LangChainRunner \\\n    --inputs question=\"What's 2+2?\" \\\n    --init custom_connection=open_ai_connection\n\n$ RUN_NAME=flex_flow_langchain-$(date +%s)\n$ pf run create \\\n    --name $RUN_NAME \\\n    --flow . \\\n    --data ./data.jsonl \\\n    --column-mapping question='${data.question}' \\\n    --stream\n\n$ pf run show-details --name $RUN_NAME\n</code></pre>"},{"location":"apps/11_promptflow/#evaluators","title":"evaluators","text":"<p>To guide you through working with evaluators, a helpful document is available at Evaluate with the prompt flow SDK.</p> <pre><code># Show help\npython apps/11_promptflow/evaluators/main.py --help\n</code></pre>"},{"location":"apps/11_promptflow/#references","title":"References","text":"<ul> <li>Repository</li> <li>examples</li> <li>Documents</li> <li>How-to Guides</li> <li>Tutorials</li> </ul>"},{"location":"apps/12_langgraph_agent/","title":"12. Create agents with LangGraph","text":"<p>This app demonstrates how to implement agents with LangGraph.</p>"},{"location":"apps/12_langgraph_agent/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.10 or later</li> <li>Azure OpenAI Service</li> </ul>"},{"location":"apps/12_langgraph_agent/#overview","title":"Overview","text":"<p>What is LangGraph?</p> <p>LangGraph is a library for building stateful, multi-actor applications with LLMs, used to create agent and multi-agent workflows.</p> <p>This chapter provides a practical example of how to use LangGraph to create an agent that can interact with users and external tools.</p>"},{"location":"apps/12_langgraph_agent/#usage","title":"Usage","text":"<ol> <li>Get Azure OpenAI Service API key</li> <li>Copy .env.template to <code>.env</code> in the same directory</li> <li>Set credentials in <code>.env</code></li> <li>Run main.py</li> </ol> <pre><code># Create a virtual environment\n$ python -m venv .venv\n\n# Activate the virtual environment\n$ source .venv/bin/activate\n\n# Install dependencies\n$ pip install -r requirements.txt\n</code></pre>"},{"location":"apps/12_langgraph_agent/#examples","title":"Examples","text":""},{"location":"apps/12_langgraph_agent/#reflection_agent","title":"reflection_agent","text":""},{"location":"apps/12_langgraph_agent/#react_agent","title":"react_agent","text":""},{"location":"apps/12_langgraph_agent/#advanced_rag_flows","title":"advanced_rag_flows","text":"<pre><code># create vector store\npython apps/12_langgraph_agent/advanced_rag_flows/ingestion.py\n\n# run main.py\npython apps/12_langgraph_agent/advanced_rag_flows/main.py\n</code></pre>"},{"location":"apps/12_langgraph_agent/#references","title":"References","text":"<ul> <li>LangGraph</li> <li>Udemy &gt; LangGraph- Develop LLM powered agents with LangGraph</li> <li>emarco177/langgaph-course</li> <li>Prompt flow &gt; Tracing</li> <li>Reflection Agents</li> <li>LangChain &gt; Reflexion</li> <li>LangChain &gt; Bing Search</li> </ul>"},{"location":"apps/13_langchain_toolkits/","title":"13. LangChain Toolkits sample applications","text":"<p>This app demonstrates how to use LangChain Toolkits.</p>"},{"location":"apps/13_langchain_toolkits/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.10 or later</li> <li>Azure OpenAI Service</li> </ul>"},{"location":"apps/13_langchain_toolkits/#overview","title":"Overview","text":"<p>What is LangChain Tools/Toolkits</p> <p>Tools are utilities designed to be called by a model: their inputs are designed to be generated by models, and their outputs are designed to be passed back to models.</p>"},{"location":"apps/13_langchain_toolkits/#usage","title":"Usage","text":"<ol> <li>Get Azure OpenAI Service API key</li> <li>Copy .env.template to <code>.env</code> in the same directory</li> <li>Set credentials in <code>.env</code></li> <li>Run main.py</li> </ol> <pre><code># Create a virtual environment\n$ python -m venv .venv\n\n# Activate the virtual environment\n$ source .venv/bin/activate\n\n# Install dependencies\n$ pip install -r requirements.txt\n</code></pre>"},{"location":"apps/13_langchain_toolkits/#examples","title":"Examples","text":""},{"location":"apps/13_langchain_toolkits/#playwright","title":"Playwright","text":""},{"location":"apps/13_langchain_toolkits/#playwright-for-python","title":"Playwright for Python","text":"<ul> <li>Test generator</li> </ul> <pre><code># Generate Python code from PlayWright\n$ npx playwright codegen --target=python\n</code></pre>"},{"location":"apps/13_langchain_toolkits/#playwright-browser-toolkit","title":"PlayWright Browser Toolkit","text":"<pre><code>$ uv run playwright install\n\n$ uv run python apps/13_langchain_toolkits/playwright_tool.py\n</code></pre> <p>Sample output:</p> <pre><code>/home/stakenaka/src/github.com/ks6088ts-labs/workshop-azure-openai/apps/13_langchain_toolkits/playwright_tool.py:7: LangChainDeprecationWarning: Importing PlayWrightBrowserToolkit from langchain.agents.agent_toolkits is deprecated. Please replace deprecated imports:\n\n&gt;&gt; from langchain.agents.agent_toolkits import PlayWrightBrowserToolkit\n\nwith new imports of:\n\n&gt;&gt; from langchain_community.agent_toolkits.playwright.toolkit import PlayWrightBrowserToolkit\nYou can use the langchain cli to **automatically** upgrade many imports. Please see documentation here &lt;https://python.langchain.com/v0.2/docs/versions/v0_2/&gt;\n  from langchain.agents.agent_toolkits import PlayWrightBrowserToolkit\n/home/stakenaka/src/github.com/ks6088ts-labs/workshop-azure-openai/apps/13_langchain_toolkits/playwright_tool.py:34: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 1.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n  agent_chain = initialize_agent(\n/home/stakenaka/src/github.com/ks6088ts-labs/workshop-azure-openai/apps/13_langchain_toolkits/playwright_tool.py:40: LangChainDeprecationWarning: The method `Chain.arun` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use ainvoke instead.\n  result = await agent_chain.arun(\"Yahoo \u30ea\u30a2\u30eb\u30bf\u30a4\u30e0\u691c\u7d22\u306e\u30c8\u30ec\u30f3\u30c9\u4e0a\u4f4d 3 \u4ef6\u3092\u6559\u3048\u3066\")\n\n\n&gt; Entering new AgentExecutor chain...\nYahoo \u30ea\u30a2\u30eb\u30bf\u30a4\u30e0\u691c\u7d22\u306e\u30c8\u30ec\u30f3\u30c9\u3092\u78ba\u8a8d\u3059\u308b\u305f\u3081\u306b\u3001\u307e\u305a\u305d\u306e\u30da\u30fc\u30b8\u306b\u30a2\u30af\u30bb\u30b9\u3057\u307e\u3059\u3002\n\nAction:\n\u2018\u2018\u2018json\n{\n  \"action\": \"navigate_browser\",\n  \"action_input\": \"https://search.yahoo.co.jp/realtime\"\n}\n\u2018\u2018\u2018\nObservation: Navigating to https://search.yahoo.co.jp/realtime returned status code 200\nThought:Action:\n\u2018\u2018\u2018json\n{\n  \"action\": \"extract_text\",\n  \"action_input\": {}\n}\n\u2018\u2018\u2018\n\nObservation: Yahoo!\u30ea\u30a2\u30eb\u30bf\u30a4\u30e0\u691c\u7d22 \u672c\u5f53\u306e\u81ea\u5206\u306a\u3093\u3066\u3001\u306a\u3044\u3002\u6771\u6d0b\u54f2\u5b66\u306b\u5b66\u3076\u300c\u81ea\u5206\u3089\u3057\u3055\u300d \u53f0\u98a8\u30fb\u8c6a\u96e8\u7de8\u3067\u306f\u5927\u96e8\u304b\u3089\u8eab\u3092\u5b88\u308b\u77e5\u8b58\u3082\u3002\u30e4\u30d5\u30fc\u9632\u707d\u6a21\u8a66\u3067\u5099\u3048\u3092 \u300c\u3053\u3053\u308d\u300d\u3068\u300c\u304b\u3089\u3060\u300d\u306e\u30ae\u30e2\u30f3\u306b\u5fdc\u3048\u308b\u300c\u30b3\u30b3\u30ab\u30e9\u5b66\u5712\u300d \u9632\u707d\u30af\u30a4\u30ba\u3067\u3001\u53f0\u98a8\u3084\u5927\u96e8\u306b\u5099\u3048\u3066\u6b63\u3057\u3044\u77e5\u8b58\u3092\u8eab\u306b\u3064\u3051\u3088\u3046\uff01 \u53f0\u98a811\u53f7\u30a2\u30b8\u30a2\u7dca\u6025\u652f\u63f4\u6d3b\u52d5\u306b\u5bc4\u4ed8\u306e\u3054\u5354\u529b\u3092\u304a\u9858\u3044\u3044\u305f\u3057\u307e\u3059 \u6700\u65b0\u707d\u5bb3\u30dc\u30e9\u30f3\u30c6\u30a3\u30a2\u60c5\u5831\u3092LINE\u3067\u53d6\u5f97 \u751f\u6210AI\u3067\u81ea\u5df1\u767a\u898b\uff1f\u3000LINE\u30e4\u30d5\u30fc\u306e\u30ad\u30e3\u30ea\u30a2\u6559\u80b2\u30d7\u30ed\u30b0\u30e9\u30e0 \u3044\u3056\u3068\u3044\u3046\u3068\u304d\u3001\u3042\u308b\u3068\u52a9\u304b\u308b\u3002#\u304a\u304f\u308b\u9632\u707d \u3010\u56f3\u89e3\u3067\u304b\u3093\u305f\u3093\u3011\u707d\u5bb3\u3054\u3068\u306b\u5f79\u7acb\u3064\u77e5\u8b58\u30fb\u6a5f\u80fd\u3092\u898b\u3066\u307f\u3088\u3046\uff01 \u30102024\u5e7410\u6708\u304b\u3089\u3011\u5150\u7ae5\u624b\u5f53\u306e\u5bfe\u8c61\u8005\u62e1\u5145\u3000\u5909\u66f4\u70b9\u306f\uff1f \u3010\u80fd\u767b\u534a\u5cf6\u8c6a\u96e8\u7dca\u6025\u652f\u63f4\u3011\u751a\u5927\u306a\u88ab\u5bb3\u304c\u51fa\u3066\u3044\u308b\u88ab\u707d\u5730\u306b\u652f\u63f4\u3092 Yahoo! JAPAN \u30d8\u30eb\u30d7 \u30ad\u30fc\u30ef\u30fc\u30c9\uff1a ID\u3067\u3082\u3063\u3068\u4fbf\u5229\u306b \u65b0\u898f\u53d6\u5f97 \u30ed\u30b0\u30a4\u30f3 \u3010\u5fc5\u305a\u3042\u305f\u308b\u3011\u304f\u3058\u5f15\u304d\u3042\u308a\u307e\u3059 JavaScript\u304c\u7121\u52b9\u3067\u3059\u3002\u30d6\u30e9\u30a6\u30b6\u306e\u8a2d\u5b9a\u3067JavaScript\u3092\u6709\u52b9\u306b\u3057\u3066\u304f\u3060\u3055\u3044\u3002 \u8a73\u3057\u304f\u306f JavaScript\u306e\u8a2d\u5b9a\u65b9\u6cd5 \u3092\u3054\u89a7\u304f\u3060\u3055\u3044\u3002 \u691c\u7d22 \u30df\u30e5\u30fc\u30c8\u3057\u305f\u30a2\u30ab\u30a6\u30f3\u30c8 \u6025\u4e0a\u6607\u30ef\u30fc\u30c9 \u3042\u306e\u540d\u66f2\u6b4c\u3063\u3066\u266a\u304a\u306d\u3060\u308a\u6b4c\u8b21\u796d \u30cf\u30f3\u30b3\u30c3\u30af \u4f50\u7530\u5bc5\u5b50 \u4f0a\u85e4\u6c99\u8389 \u30c8\u30ec\u30f3\u30c9 9:50 \u66f4\u65b0 1 \u4f50\u7530\u5bc5\u5b50 2 \u5929\u7a7a\u306e\u82b1\u5ac1 3 \u8ecd\u306f\u96a0\u853d 4 \u88cf\u91d1\u5185\u95a3 5 \u526f\u696d\u89e3\u7981 6 \u7d75\u4e16\u754c\u7269\u8a9e 7 \u3055\u3088\u30fc\u306a\u3089\u307e\u305f\u3044\u3064\u304b 8 \u4ecb\u8b77\u4f53\u9a13 9 \u30cf\u30f3\u30b3\u30c3\u30af 10 \u5730\u7344\u306e\u9053 11 \u81ea\u6c11\u30fb\u9ebb\u751f\u526f\u7dcf\u88c1\u304c\u9ad8\u5e02\u6c0f\u652f\u6301\u3078 12 \u4f0a\u85e4\u6c99\u8389 13 \u5fa1\u5dbd\u5c71\u5674\u706b 14 \u30de\u30c3\u30b5\u30de\u30f3 15 \u30d7\u30ec\u30df\u30a2\u30e0\u30d5\u30e9\u30a4\u30c7\u30fc 16 \u5c0f\u5ddd\u5f69\u4f73\u30a2\u30ca 17 \u864e\u306b\u7ffc\u6700\u7d42\u56de 18 \u4e09\u5b85\u30a2\u30ca 19 \u4e16\u754c\u89b3\u5149\u306e\u65e5 20 \u3042\u306e\u540d\u66f2\u6b4c\u3063\u3066\u266a\u304a\u306d\u3060\u308a\u6b4c\u8b21\u796d \u4eba\u6c17\u30dd\u30b9\u30c8 \u300c\u307e\u308b\u3067\u6771\u4eac\u30bf\u30ef\u30fc\u3092\u6a2a\u306b\u5012\u3057\u305f\u3088\u3046\u300d \u3000\u3000\u3000 \u30ea\u30ea\u30fc\u30fb\u30d5\u30e9\u30f3\u30ad\u30fc\u6c0f\u304c \u30d9\u30b9\u30c8\u30bb\u30e9\u30fc\u300e\u6771\u4eac\u30bf\u30ef\u30fc\u300f\u3067 \u3053\u3046\u5f62\u5bb9\u3057\u305f\uff1c\u5317\u4e5d\u5dde\u5e02\u306e\u30b7\u30f3\u30dc\u30eb\uff1e\u3068\u3044\u3048\u3070\uff1f \u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000 \u3010\u30d2\u30f3\u30c8\u3011 \u30fb\u65e5\u672c\u306e\u3064\u308a\u6a4b\u306e\u5148\u99c6\u3051 \u30fb\u5efa\u8a2d\u5f53\u6642\u306e\u79f0\u53f7\u300c\u6771\u6d0b\u4e00\u306e\u5922\u306e\u3064\u308a\u6a4b\u300d \u30fb\u82e5\u677e\u533a\u3068\u6238\u7551\u533a\u3092\u7d50\u3076\u8d64\u3044\u6a4b  \u6b63\u89e3\u306f\u2026\u2026 \u8fd4\u4fe1\u6570 33 \u30ea\u30dd\u30b9\u30c8\u6570 118 \u3044\u3044\u306d\u6570 356 3\u6642\u9593\u524d \u30b9\u30dd\u30f3\u30b8\u30b1\u30fc\u30ad\u3092\u4f7f\u3046\u304a\u83d3\u5b50\u306f\u4e38\u3044\u30b1\u30fc\u30ad\u3057\u304b\u77e5\u3089\u306a\u304b\u3063\u305f\u3093\u3067\u3059\u304c\u3001\u30b7\u30e3\u30a4\u30f3\u30de\u30b9\u30ab\u30c3\u30c8\u30b1\u30fc\u30ad\u3092\u4f5c\u308b\u6642\u306b\u8272\u3005\u8abf\u3079\u3066\u307f\u308b\u3068\u3001\u56db\u89d2\u3044\u30b1\u30fc\u30ad\u3082\u3042\u308b\u3093\u3067\u3059\u306d\u3047\ud83e\udd14  \u3068\u3044\u3046\u3053\u3068\u3067\u4eca\u56de\u306f\u56db\u89d2\u3044\u30b9\u30dd\u30f3\u30b8\u30b1\u30fc\u30ad\u306e\u30ec\u30b7\u30d4\u3092\u7d39\u4ecb\u3057\u307e\u3059\ud83d\ude06  \ud83d\udc47\u8a73\u3057\u3044\u4f5c\u308a\u65b9\u306f\ud83d\udc47 bit.ly/3UgAMgc  #\u304a\u83d3\u5b50\u4f5c\u308a #sweets \u8fd4\u4fe1\u6570 7 \u30ea\u30dd\u30b9\u30c8\u6570 158 \u3044\u3044\u306d\u6570 406 2\u6642\u9593\u524d \u30b3\u30a2\u306e\u30a8\u30b4\u30b5\u529b\u306a\u3089\u3059\u3050\u898b\u3064\u3051\u308b\u3060\u308d\u3046\u306a\u3068\u601d\u3063\u305f\u3088\u3002 \u8a72\u5f53\u306e\u307f\u3093\u306a\u306b\u5c4a\u304d\u307e\u3059\u3088\u3046\u306b\u3002 \u8fd4\u4fe1\u6570 1 \u30ea\u30dd\u30b9\u30c8\u6570 158 \u3044\u3044\u306d\u6570 860 9\u6642\u9593\u524d \u7121\u8077\u306e\u9593\u306a\u306b\u3092\u3057\u3066\u305f\u304b\u3068\u3044\u3046\u3068\u6bce\u671d\u3001\u6563\u6b69\u3057\u30663\u6642\u306b\u306f\u3064\u304f\u3063\u305f\u304a\u3084\u3064\u3092\u98df\u3079\u3066\u3044\u307e\u3057\u305f\u3002\u6709\u96e3\u3044\u3053\u3068\u3067\u3059\u3002 \u8fd4\u4fe1\u6570 2 \u30ea\u30dd\u30b9\u30c8\u6570 123 \u3044\u3044\u306d\u6570 3,164 12\u6642\u9593\u524d \u4eca\u65e5\u306e\u30d1\u30b9\u30bf\u306a\u3093\u304b\u786c\u304f\u3066\u6298\u308a\u306b\u304f\u3044\u306a\u3068\u601d\u3063\u305f\u3089\u83dc\u7bb8\u3082\u4e00\u7dd2\u306b\u6298\u3063\u3066\u305f\u3002\u6700\u60aa\u3059\u304e\u308b\u3002 \u8fd4\u4fe1\u6570 41 \u30ea\u30dd\u30b9\u30c8\u6570 3,524 \u3044\u3044\u306d\u6570 30,436 12\u6642\u9593\u524d \u4eca\u307e\u3067\u30b5\u30d6\u30b9\u30af\u306b\u306a\u304f\u3066\u3001\u3064\u3044\u6700\u8fd1\u30ec\u30f3\u30bf\u30eb\u3057\u305f\u306e\u306b\u4eca\u65e5\u304b\u3089\u30cd\u30c8\u30d5\u30ea\u3067\u914d\u4fe1\u306b\u306a\u3063\u3066\u305f\ud83d\ude2d\ud83d\ude2d\ud83d\ude2d \u8fd4\u4fe1\u6570 5 \u30ea\u30dd\u30b9\u30c8\u6570 269 \u3044\u3044\u306d\u6570 6,873 14\u6642\u9593\u524d \u3084\u3063\u3071\u3053\u308c\u4f55\u56de\u898b\u3066\u3082\u6307\u3055\u3059\u3068\u3053\u305d\u3053\u3058\u3083\u306a\u3044 \u8fd4\u4fe1\u6570 1 \u30ea\u30dd\u30b9\u30c8\u6570 203 \u3044\u3044\u306d\u6570 1,431 15\u6642\u9593\u524d \u307e\u3060\u77e5\u4e8b\u3067\u3044\u305f\u3044\u3068\u99c4\u3005\u3092\u3053\u306d\u308b46\u6b73\u5150\u304c\u3053\u3061\u3089\u3002 \u8fd4\u4fe1\u6570 63 \u30ea\u30dd\u30b9\u30c8\u6570 327 \u3044\u3044\u306d\u6570 1,731 17\u6642\u9593\u524d \u304a\u3058\u3044\u3061\u3083\u3093\u3059\u304e\u308bwww \u8fd4\u4fe1\u6570 10 \u30ea\u30dd\u30b9\u30c8\u6570 104 \u3044\u3044\u306d\u6570 1,583 1\u65e5\u524d \u670d\u7740\u3066\u3066\u3082\u3080\u3061\u3080\u3061\u96a0\u305b\u3066\u306a\u3044\u3063\u3066\u8a00\u308f\u308c\u305f \u8fd4\u4fe1\u6570 29 \u30ea\u30dd\u30b9\u30c8\u6570 133 \u3044\u3044\u306d\u6570 4,211 14\u6642\u9593\u524d \u3082\u3063\u3068\u898b\u308b \u96fb\u8eca\u9045\u5ef6 \uff08\u5728\u6765\u7dda\u3001\u79c1\u9244\u3001\u5730\u4e0b\u9244\uff09 \u5317\u6d77\u9053 \u6771\u5317 \u95a2\u6771 \u4e2d\u90e8 \u8fd1\u757f \u4e2d\u56fd \u56db\u56fd \u4e5d\u5dde \u6771\u6025\u7530\u5712\u90fd\u5e02\u7dda \u929a\u5b50\u96fb\u9244\u7dda \u6771\u6b66\u30b9\u30ab\u30a4\u30c4\u30ea\u30fc\u30e9\u30a4\u30f3 \u5168\u56fd\u306e\u904b\u884c\u60c5\u5831\uff08Yahoo!\u8def\u7dda\u60c5\u5831\uff09 \u30df\u30e5\u30fc\u30c8\u3057\u305f\u30a2\u30ab\u30a6\u30f3\u30c8 \u30d7\u30e9\u30a4\u30d0\u30b7\u30fc\u30dd\u30ea\u30b7\u30fc \u30d7\u30e9\u30a4\u30d0\u30b7\u30fc\u30bb\u30f3\u30bf\u30fc \u5229\u7528\u898f\u7d04 \u5e83\u544a\u306b\u3064\u3044\u3066 \u691c\u7d22\u30b5\u30fc\u30d3\u30b9\u4e00\u89a7 \u30d8\u30eb\u30d7\u30fb\u304a\u554f\u3044\u5408\u308f\u305b \u30e9\u30f3\u30ad\u30f3\u30b0\u60c5\u5831\u306eAPI\u63d0\u4f9b X\uff08\u65e7Twitter\uff09\u30c7\u30fc\u30bf\u306b\u3064\u3044\u3066 Copyright (C) 2024 LY Corporation. All Rights Reserved.\nThought:Action:\n\u2018\u2018\u2018json\n{\n  \"action\": \"Final Answer\",\n  \"action_input\": \"Yahoo\u30ea\u30a2\u30eb\u30bf\u30a4\u30e0\u691c\u7d22\u306e\u30c8\u30ec\u30f3\u30c9\u4e0a\u4f4d3\u4ef6\u306f\u4ee5\u4e0b\u306e\u901a\u308a\u3067\u3059\uff1a\\n1. \u4f50\u7530\u5bc5\u5b50\\n2. \u5929\u7a7a\u306e\u82b1\u5ac1\\n3. \u8ecd\u306f\u96a0\u853d\"\n}\n\u2018\u2018\u2018\n\n&gt; Finished chain.\nYahoo\u30ea\u30a2\u30eb\u30bf\u30a4\u30e0\u691c\u7d22\u306e\u30c8\u30ec\u30f3\u30c9\u4e0a\u4f4d3\u4ef6\u306f\u4ee5\u4e0b\u306e\u901a\u308a\u3067\u3059\uff1a\n1. \u4f50\u7530\u5bc5\u5b50\n2. \u5929\u7a7a\u306e\u82b1\u5ac1\n3. \u8ecd\u306f\u96a0\u853d\n</code></pre> <ul> <li>PlayWright Browser Toolkit \u3067 Web \u30b9\u30af\u30ec\u30a4\u30d4\u30f3\u30b0\u3092\u8a66\u3057\u3066\u307f\u305f</li> </ul>"},{"location":"apps/14_streamlit_azure_ai_speech/","title":"14. Realtime transcription with Azure AI Speech Service","text":"<p>This app demonstrates how to use Azure AI Speech Service for realtime transcription.</p>"},{"location":"apps/14_streamlit_azure_ai_speech/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.10 or later</li> <li>Azure AI Speech Service</li> <li>Azure OpenAI Service</li> </ul>"},{"location":"apps/14_streamlit_azure_ai_speech/#overview","title":"Overview","text":"<pre><code># Speech to Text script\nuv run python apps/14_streamlit_azure_ai_speech/speech_to_text.py --help\n\n# WIP: Streamlit app\nuv run python -m streamlit run apps/14_streamlit_azure_ai_speech/main.py\n</code></pre>"},{"location":"apps/14_streamlit_azure_ai_speech/#references","title":"References","text":"<ul> <li>How to recognize speech</li> <li>Quickstart: Create real-time diarization</li> <li>Speech to text containers with Docker</li> <li>AzureSpeechService \u3067\u30ea\u30a2\u30eb\u30bf\u30a4\u30e0\u8b70\u4e8b\u9332</li> </ul>"},{"location":"apps/15_streamlit_chat_slm/","title":"15. Streamlit Chat with SLM","text":""},{"location":"apps/15_streamlit_chat_slm/#overview","title":"Overview","text":"<pre><code># Run Ollama server\n$ ollama serve\n\n# Pull Phi3 model\n$ ollama pull phi3\n\n# Run a simple chat with Ollama\n$ uv run python apps/15_streamlit_chat_slm/chat.py\n\n# Run summarization with SLM\n$ uv run python apps/15_streamlit_chat_slm/summarize.py\n\n# Run streamlit app\n$ uv run python -m streamlit run apps/15_streamlit_chat_slm/main.py\n\n# List models\n$ ollama list\nNAME           ID              SIZE      MODIFIED\nphi3:latest    4f2222927938    2.2 GB    3 minutes ago\nphi4:latest    ac896e5b8b34    9.1 GB    55 minutes ago\n</code></pre>"},{"location":"apps/15_streamlit_chat_slm/#usage","title":"Usage","text":""},{"location":"apps/15_streamlit_chat_slm/#use-phi3-model","title":"Use Phi3 model","text":"<pre><code># Pull Phi3 model\n$ ollama pull phi3\n\n# Measure time to run the chat\n$ time uv run python apps/15_streamlit_chat_slm/chat.py \\\n  --model phi3 \\\n  --prompt \"hello\"\n{\n  \"content\": \"Hello! How can I help you today?\",\n  \"additional_kwargs\": {},\n  \"response_metadata\": {\n    \"model\": \"phi3\",\n    \"created_at\": \"2025-01-09T03:30:05.706397262Z\",\n    \"message\": {\n      \"role\": \"assistant\",\n      \"content\": \"\"\n    },\n    \"done_reason\": \"stop\",\n    \"done\": true,\n    \"total_duration\": 540964618,\n    \"load_duration\": 5078297,\n    \"prompt_eval_count\": 22,\n    \"prompt_eval_duration\": 229000000,\n    \"eval_count\": 10,\n    \"eval_duration\": 305000000\n  },\n  \"type\": \"ai\",\n  \"name\": null,\n  \"id\": \"run-54f0d2a6-b3d4-4ef5-b009-0c72b23297ac-0\",\n  \"example\": false,\n  \"tool_calls\": [],\n  \"invalid_tool_calls\": [],\n  \"usage_metadata\": {\n    \"input_tokens\": 22,\n    \"output_tokens\": 10,\n    \"total_tokens\": 32\n  }\n}\nuv run python apps/15_streamlit_chat_slm/chat.py --model phi3 --prompt   1.57s user 0.16s system 68% cpu 2.515 total\n</code></pre>"},{"location":"apps/15_streamlit_chat_slm/#use-phi4-model","title":"Use Phi4 model","text":"<pre><code># Pull Phi4 model\n$ ollama pull phi4\n\n# Measure time to run the chat\n$ time uv run python apps/15_streamlit_chat_slm/chat.py \\\n  --model phi4 \\\n  --prompt \"hello\"\n{\n  \"content\": \"Hello! How can I assist you today? If you have any questions or need information, feel free to let me know. \ud83d\ude0a\",\n  \"additional_kwargs\": {},\n  \"response_metadata\": {\n    \"model\": \"phi4\",\n    \"created_at\": \"2025-01-09T03:16:19.661532868Z\",\n    \"message\": {\n      \"role\": \"assistant\",\n      \"content\": \"\"\n    },\n    \"done_reason\": \"stop\",\n    \"done\": true,\n    \"total_duration\": 10662476906,\n    \"load_duration\": 10769327,\n    \"prompt_eval_count\": 23,\n    \"prompt_eval_duration\": 426000000,\n    \"eval_count\": 28,\n    \"eval_duration\": 10223000000\n  },\n  \"type\": \"ai\",\n  \"name\": null,\n  \"id\": \"run-16375018-116e-422f-afd4-84692af42bd6-0\",\n  \"example\": false,\n  \"tool_calls\": [],\n  \"invalid_tool_calls\": [],\n  \"usage_metadata\": {\n    \"input_tokens\": 23,\n    \"output_tokens\": 28,\n    \"total_tokens\": 51\n  }\n}\nuv run python apps/15_streamlit_chat_slm/chat.py --model phi4 --prompt   1.48s user 0.12s system 12% cpu 12.455 total\n</code></pre> <p>Note:</p> <ul> <li>Update Ollama to the latest version to run phi4 model</li> <li>To use Ollama on WSL2, you may need to enable systemd. For more information, see Use systemd to manage Linux services with WSL</li> </ul>"},{"location":"apps/15_streamlit_chat_slm/#references","title":"References","text":"<ul> <li>ChatOllama</li> <li>Summarize Text</li> </ul>"},{"location":"apps/16_whisper_transcription/","title":"16. Whisper transcription","text":""},{"location":"apps/16_whisper_transcription/#references","title":"References","text":"<ul> <li>openai/whisper</li> <li>Improve --model argument handling and help message #1764</li> </ul>"},{"location":"apps/1_call_azure_openai_chat/","title":"1. Call Azure OpenAI Service API from Python","text":"<p>This app demonstrates how to call the Azure OpenAI Service API from Python.</p>"},{"location":"apps/1_call_azure_openai_chat/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.10 or later</li> <li>Azure OpenAI Service</li> </ul>"},{"location":"apps/1_call_azure_openai_chat/#overview","title":"Overview","text":"<p>To call Azure OpenAI Service API, you can send HTTP requests directly to the API endpoint or use the OpenAI Python API library.</p> <p>Send HTTP requests directly to the API endpoint</p> <pre><code>YOUR_AOAI_NAME=\"your-aoai-name\"\nYOUR_DEPLOYMENT_ID=\"your-deployment-id\"\nYOUR_API_KEY=\"your-api-key\"\n\ncurl -X 'POST' \\\n  \"https://$YOUR_AOAI_NAME.openai.azure.com/openai/deployments/$YOUR_DEPLOYMENT_ID/chat/completions?api-version=2023-12-01-preview\" \\\n  -H \"api-key: $YOUR_API_KEY\" \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n    \"messages\": [\n      {\"role\": \"user\", \"content\": \"What is the weather like in Boston and New York?\"}\n    ]\n  }'\n</code></pre> <p>Use OpenAI Python API library</p> <pre><code># Import modules\nfrom os import getenv\nfrom openai import AzureOpenAI\n\n# Initialize AzureOpenAI client\nclient = AzureOpenAI(\n    api_key=getenv(\"AZURE_OPENAI_API_KEY\"),\n    api_version=getenv(\"AZURE_OPENAI_API_VERSION\"),\n    azure_endpoint=getenv(\"AZURE_OPENAI_ENDPOINT\"),\n)\n\n# Call completion API and get a response to user input\nresponse = client.chat.completions.create(\n    model=getenv(\"AZURE_OPENAI_GPT_MODEL\"),\n    messages=[\n        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n        {\"role\": \"user\", \"content\": \"Hello\"},\n    ],\n)\n</code></pre> <p>For more information, see the following references.</p> <ul> <li>API Reference: Azure OpenAI Service REST API reference</li> <li>OpenAPI Spec: Cognitive Services AzureOpenAI SDKs.</li> </ul>"},{"location":"apps/1_call_azure_openai_chat/#usage","title":"Usage","text":"<ol> <li>Get Azure OpenAI Service API key</li> <li>Copy .env.template to <code>.env</code> in the same directory</li> <li>Set credentials in <code>.env</code></li> <li>Run scripts</li> </ol> <pre><code># Create a virtual environment\n$ python -m venv .venv\n\n# Activate the virtual environment\n$ source .venv/bin/activate\n\n# Install dependencies\n$ pip install -r requirements.txt\n\n# Run the script\n$ python apps/1_call_azure_openai_chat/main.py\n</code></pre>"},{"location":"apps/1_call_azure_openai_chat/#mainpy","title":"main.py","text":"<p>To call the Azure OpenAI Service API, run the following command.</p> <p>Detailed information is described in the Quickstart: Get started using GPT-35-Turbo and GPT-4 with Azure OpenAI Service.</p> <pre><code>$ python apps/1_call_azure_openai_chat/main.py\n{\n  \"id\": \"chatcmpl-9tVzJwEczzb40cXT1gHZkk7ThX5Lm\",\n  \"choices\": [\n    {\n      \"finish_reason\": \"stop\",\n      \"index\": 0,\n      \"logprobs\": null,\n      \"message\": {\n        \"content\": \"Hello! How can I assist you today?\",\n        \"role\": \"assistant\",\n        \"function_call\": null,\n        \"tool_calls\": null\n      },\n      \"content_filter_results\": {\n        \"hate\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"protected_material_code\": {\n          \"filtered\": false,\n          \"detected\": false\n        },\n        \"protected_material_text\": {\n          \"filtered\": false,\n          \"detected\": false\n        },\n        \"self_harm\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"sexual\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"violence\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        }\n      }\n    }\n  ],\n  \"created\": 1723018029,\n  \"model\": \"gpt-4o-2024-05-13\",\n  \"object\": \"chat.completion\",\n  \"service_tier\": null,\n  \"system_fingerprint\": \"fp_abc28019ad\",\n  \"usage\": {\n    \"completion_tokens\": 9,\n    \"prompt_tokens\": 18,\n    \"total_tokens\": 27\n  },\n  \"prompt_filter_results\": [\n    {\n      \"prompt_index\": 0,\n      \"content_filter_results\": {\n        \"hate\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"jailbreak\": {\n          \"filtered\": false,\n          \"detected\": false\n        },\n        \"self_harm\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"sexual\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"violence\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        }\n      }\n    }\n  ]\n}\n</code></pre>"},{"location":"apps/1_call_azure_openai_chat/#references","title":"References","text":"<ul> <li>Python basics</li> <li>Python Cheatsheet &gt; Basics</li> <li>venv \u2014 Creation of virtual environments</li> <li>Azure OpenAI Basics</li> <li>Azure OpenAI Service documentation</li> <li>Quickstart: Get started generating text using Azure OpenAI Service</li> </ul>"},{"location":"apps/1_call_azure_openai_chat/#convert_codepy","title":"convert_code.py","text":"<p>Support for structured outputs was first added in API version 2024-08-01-preview. It is available in the latest preview APIs as well as the latest GA API: 2024-10-21. See details in Structured outputs.</p> <p>To set up the environment, run the following commands.</p> <pre><code># Create a virtual environment\npython -m venv .venv\n\n# Activate the virtual environment\nsource .venv/bin/activate\n\n# Install dependencies\npip install openai python-dotenv pydantic langchain-openai\n</code></pre> <p>Run the following command to convert code via OpenAI SDK or LangChain.</p> <pre><code>\n# help\npython apps/1_call_azure_openai_chat/convert_code.py --help\n\n# convert code via OpenAI SDK in verbose mode\npython apps/1_call_azure_openai_chat/convert_code.py \\\n  --system \"Extract the event information.\" \\\n  --user \"Alice and Bob are going to a science fair on Friday.\" \\\n  --type \"openai\" \\\n  --verbose\n# Result: name='Science Fair' date='Friday' participants=['Alice', 'Bob']\n\n# convert code via LangChain in verbose mode\npython apps/1_call_azure_openai_chat/convert_code.py \\\n  --system \"Extract the event information.\" \\\n  --user \"Alice and Bob are going to a science fair on Friday.\" \\\n  --type \"langchain\" \\\n  --verbose\n# Result: name='Science Fair' date='Friday' participants=['Alice', 'Bob']\n</code></pre>"},{"location":"apps/1_call_azure_openai_chat/#references_1","title":"References","text":"<ul> <li>Structured outputs</li> <li>How to return structured data from a model</li> </ul>"},{"location":"apps/2_streamlit_chat/","title":"2. Create an Azure OpenAI Chat app using Streamlit","text":"<p>This app demonstrates how to create a chat application using Azure OpenAI Service and Streamlit.</p>"},{"location":"apps/2_streamlit_chat/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.10 or later</li> <li>Azure OpenAI Service</li> </ul>"},{"location":"apps/2_streamlit_chat/#overview","title":"Overview","text":"<p>In this app, you learn how to create an app with Streamlit.</p> <p>Streamlit is an open-source Python library that makes it easy to create and share beautiful, custom web apps for machine learning and data science projects. It allows you to build interactive applications with minimal code (only in Python!!), focusing on rapid prototyping and simplicity.</p> <p>To get started, it is recommended to go through the Streamlit documentation to create your first hello world app.</p> <pre><code># Go to some directory\ncd tmp\n\n# Create a virtual environment\npython -m venv .venv\n\n# Activate the virtual environment\nsource .venv/bin/activate\n\n# Install Streamlit\npip install streamlit\n\n# Run the hello world python script from local file, described below\nstreamlit run ./hello.py\n</code></pre> <p>Create a \"Hello World\" app and run it</p> <pre><code>import streamlit as st\n\nst.write(\"Hello world\")\n</code></pre> <p>To go further, you can refer to the API reference to understand the different components and functionalities available in Streamlit. You can also refer to the Streamlit Cheat Sheet. There are many examples and tutorials available on the Streamlit website.</p> <p>Create a chat application</p> <p>For implementing the chat application, you can refer to the Streamlit Chat example below. This app uses the OpenAI API to create a chatbot that can chat with users. The chatbot uses the GPT-3.5-turbo model to generate responses.</p> <pre><code>import streamlit as st\nfrom openai import OpenAI\n\nwith st.sidebar:\n    openai_api_key = st.text_input(\"OpenAI API Key\", key=\"chatbot_api_key\", type=\"password\")\n    \"[Get an OpenAI API key](https://platform.openai.com/account/api-keys)\"\n    \"[View the source code](https://github.com/streamlit/llm-examples/blob/main/Chatbot.py)\"\n    \"[![Open in GitHub Codespaces](https://github.com/codespaces/badge.svg)](https://codespaces.new/streamlit/llm-examples?quickstart=1)\"\n\nst.title(\"\ud83d\udcac Chatbot\")\n\nif \"messages\" not in st.session_state:\n    st.session_state[\"messages\"] = [{\"role\": \"assistant\", \"content\": \"How can I help you?\"}]\n\nfor msg in st.session_state.messages:\n    st.chat_message(msg[\"role\"]).write(msg[\"content\"])\n\nif prompt := st.chat_input():\n    if not openai_api_key:\n        st.info(\"Please add your OpenAI API key to continue.\")\n        st.stop()\n\n    client = OpenAI(api_key=openai_api_key)\n    st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n    st.chat_message(\"user\").write(prompt)\n    response = client.chat.completions.create(model=\"gpt-3.5-turbo\", messages=st.session_state.messages)\n    msg = response.choices[0].message.content\n    st.session_state.messages.append({\"role\": \"assistant\", \"content\": msg})\n    st.chat_message(\"assistant\").write(msg)\n</code></pre>"},{"location":"apps/2_streamlit_chat/#exercise-convert-openai-api-to-azure-openai-service","title":"Exercise: Convert OpenAI API to Azure OpenAI Service","text":"<p>In this exercise, please convert the OpenAI API to the Azure OpenAI Service API with the knowledge you have gained from the previous chapter 1_call_azure_openai_chat.</p>"},{"location":"apps/2_streamlit_chat/#usage","title":"Usage","text":"<ol> <li>Get Azure OpenAI Service API key</li> <li>Copy .env.template to <code>.env</code> in the same directory</li> <li>Set credentials in <code>.env</code></li> <li>Run main.py</li> </ol> <pre><code># Create a virtual environment\n$ python -m venv .venv\n\n# Activate the virtual environment\n$ source .venv/bin/activate\n\n# Install dependencies\n$ pip install -r requirements.txt\n\n# Run the script\n$ python -m streamlit run apps/2_streamlit_chat/main.py\n</code></pre>"},{"location":"apps/2_streamlit_chat/#example","title":"Example","text":"<p>When you access <code>http://localhost:8501</code>, you will see the following screen.</p> <p></p> <p>To start a conversation, fill in the required fields in the sidebar and you will see the following screen.</p> <p></p>"},{"location":"apps/2_streamlit_chat/#note","title":"Note","text":"<p>This app uses <code>st.session_state.messages</code> to store messages for chat. This is a mechanism to store messages per session on the process side of the application. Messages will disappear when the session ends.</p>"},{"location":"apps/3_call_azure_cosmos_db/","title":"3. Call Azure Cosmos DB from Python","text":"<p>This app demonstrates how to call Azure Cosmos DB from Python.</p>"},{"location":"apps/3_call_azure_cosmos_db/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.10 or later</li> <li>Azure Cosmos DB</li> </ul>"},{"location":"apps/3_call_azure_cosmos_db/#usage","title":"Usage","text":"<ol> <li>Create an Azure Cosmos DB account</li> <li>Get the connection string for Azure Cosmos DB</li> <li>Copy .env.template to <code>.env</code> in the same directory</li> <li>Set credentials in <code>.env</code></li> <li>Run main.py</li> </ol> <pre><code># Create a virtual environment\n$ python -m venv .venv\n\n# Activate the virtual environment\n$ source .venv/bin/activate\n\n# Install dependencies\n$ pip install -r requirements.txt\n\n# Run the script\n$ python apps/3_call_azure_cosmos_db/main.py Hello\n</code></pre>"},{"location":"apps/3_call_azure_cosmos_db/#example","title":"Example","text":"<pre><code>$ python apps/3_call_azure_cosmos_db/main.py --command create\nCreate item\n{'_attachments': 'attachments/',\n '_etag': '\"0000ef9c-0000-2300-0000-66dfd5140000\"',\n '_rid': 'ipcwAJFKMxICAAAAAAAAAA==',\n '_self': 'dbs/ipcwAA==/colls/ipcwAJFKMxI=/docs/ipcwAJFKMxICAAAAAAAAAA==/',\n '_ts': 1725945108,\n 'content': 'Hello, world!',\n 'id': 'test',\n 'role': 'assistant'}\n\n$ python apps/3_call_azure_cosmos_db/main.py --command read\nRead item:\n{'_attachments': 'attachments/',\n '_etag': '\"0000ef9c-0000-2300-0000-66dfd5140000\"',\n '_rid': 'ipcwAJFKMxICAAAAAAAAAA==',\n '_self': 'dbs/ipcwAA==/colls/ipcwAJFKMxI=/docs/ipcwAJFKMxICAAAAAAAAAA==/',\n '_ts': 1725945108,\n 'content': 'Hello, world!',\n 'id': 'test',\n 'role': 'assistant'}\n\n$ python apps/3_call_azure_cosmos_db/main.py --command delete\nDelete item:\n\n$ python apps/3_call_azure_cosmos_db/main.py --command read\nRead item:\nFailed to read item: (NotFound) Entity with the specified id does not exist in the system. More info: https://aka.ms/cosmosdb-tsg-not-found,\n</code></pre>"},{"location":"apps/3_call_azure_cosmos_db/#references","title":"References","text":"<ul> <li>Get started with Azure Cosmos DB for NoSQL using Python</li> <li>Examples for Azure Cosmos DB for NoSQL SDK for Python</li> <li>Azure Cosmos DB SQL API client library for Python Samples</li> </ul>"},{"location":"apps/4_streamlit_chat_history/","title":"4. Add feature to store chat history using Azure Cosmos DB","text":"<p>This app demonstrates how to add a feature to save chat history using Azure Cosmos DB to an Azure OpenAI Chat app using Streamlit implemented in 2_streamlit_chat.</p>"},{"location":"apps/4_streamlit_chat_history/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.10 or later</li> <li>Azure OpenAI Service</li> <li>Azure Cosmos DB</li> </ul>"},{"location":"apps/4_streamlit_chat_history/#usage","title":"Usage","text":"<ol> <li>Get Azure OpenAI Service API key</li> <li>Get the connection string for Azure Cosmos DB</li> <li>Copy .env.template to <code>.env</code> in the same directory</li> <li>Set credentials in <code>.env</code></li> <li>Run main.py</li> </ol> <pre><code># Create a virtual environment\n$ python -m venv .venv\n\n# Activate the virtual environment\n$ source .venv/bin/activate\n\n# Install dependencies\n$ pip install -r requirements.txt\n\n# Run the script\n$ python -m streamlit run apps/4_streamlit_chat_history/main.py\n</code></pre>"},{"location":"apps/4_streamlit_chat_history/#example","title":"Example","text":"<p>Access <code>http://localhost:8501</code> and set the required fields in the sidebar to start a conversation.</p> <p>When you send a message, the chat history will be saved in Azure Cosmos DB.</p> <p></p> <p>Conversation history can be viewed from the Cosmos DB Data Explorer as shown below.</p> <p></p> <p>The chat history is saved as shown below.</p> <p>Conversation #1</p> <pre><code>{\n  \"id\": \"1616ec81774f4a81b75038edfe493df3\",\n  \"session_id\": \"2b083432-39b5-49d6-a14a-8ea341bbb0e0\",\n  \"messages\": [\n    {\n      \"role\": \"assistant\",\n      \"content\": \"Hello! I'm a helpful assistant.\"\n    },\n    {\n      \"role\": \"user\",\n      \"content\": \"Hello how are you ?\"\n    },\n    {\n      \"role\": \"assistant\",\n      \"content\": \"Hello! I'm just a program, so I don't have feelings, but I'm here and ready to help you with whatever you need. How can I assist you today?\"\n    }\n  ],\n  \"_rid\": \"Ny9FAOMmTIMLAAAAAAAAAA==\",\n  \"_self\": \"dbs/Ny9FAA==/colls/Ny9FAOMmTIM=/docs/Ny9FAOMmTIMLAAAAAAAAAA==/\",\n  \"_etag\": \"\\\"8100214b-0000-2300-0000-66b331fe0000\\\"\",\n  \"_attachments\": \"attachments/\",\n  \"_ts\": 1723019774\n}\n</code></pre> <p>Conversation #2</p> <pre><code>{\n  \"id\": \"417ff09c764a45099a2b08618225cf57\",\n  \"session_id\": \"2b083432-39b5-49d6-a14a-8ea341bbb0e0\",\n  \"messages\": [\n    {\n      \"role\": \"assistant\",\n      \"content\": \"Hello! I'm a helpful assistant.\"\n    },\n    {\n      \"role\": \"user\",\n      \"content\": \"Hello how are you ?\"\n    },\n    {\n      \"role\": \"assistant\",\n      \"content\": \"Hello! I'm just a program, so I don't have feelings, but I'm here and ready to help you with whatever you need. How can I assist you today?\"\n    },\n    {\n      \"role\": \"user\",\n      \"content\": \"describe what Microsoft is\"\n    },\n    {\n      \"role\": \"assistant\",\n      \"content\": \"Microsoft Corporation is an American multinational technology company that develops, manufactures, licenses, supports, and sells a wide range of software, services, devices, and solutions. It was founded by Bill Gates and Paul Allen on April 4, 1975. Here are some key aspects of Microsoft:\\n\\n### Key Products and Services:\\n\\n1. **Windows Operating System**:\\n   - Microsoft Windows is one of the most widely used operating systems for personal computers and servers. Various versions include Windows 10, Windows 11, and earlier versions such as Windows XP and Windows 7.\\n\\n2. **Microsoft Office Suite**:\\n   - Office is a suite of productivity applications that includes Word (word processing), Excel (spreadsheets), PowerPoint (presentations), Outlook (email and calendar), and more. Office is available both as a one-time purchase and as a subscription service known as Microsoft 365.\\n\\n3. **Azure**:\\n   - Microsoft Azure is a cloud computing platform and service used for building, testing, deploying, and managing applications and services through Microsoft-managed data centers.\\n\\n4. **Surface Devices**:\\n   - Microsoft Surface is a series of touchscreen personal computers and interactive whiteboards, which include tablets, laptops, and desktop PCs.\\n\\n5. **Xbox**:\\n   - Xbox is a gaming console brand created and owned by Microsoft. It includes consoles like the Xbox One, Xbox Series X, and Xbox Series S.\\n\\n6. **LinkedIn**:\\n   - A professional networking platform that Microsoft acquired in 2016.\\n\\n7. **GitHub**:\\n   - A web-based platform for version control and collaboration, primarily for software development. Microsoft acquired GitHub in 2018.\\n\\n8. **Teams**:\\n   - Microsoft Teams is a collaboration platform that combines workplace chat, meetings, notes, and attachments. It integrates with Microsoft Office 365.\\n\\n### Corporate Information:\\n- **Headquarters**: Redmond, Washington, USA\\n- **CEO**: As of the last update, Satya Nadella (took over the role in 2014)\\n\\n### Innovations and Contributions:\\n- **Artificial Intelligence (AI)** and **Machine Learning (ML)** solutions.\\n- **Quantum Computing** research and development.\\n- Investments in educational tools and initiatives.\\n- Various contributions to open source software.\\n\\nOverall, Microsoft is a key player in the tech industry, contributing significantly to various technological advancements and offering a wide array of products and services that impact both consumers and businesses around the world.\"\n    }\n  ],\n  \"_rid\": \"Ny9FAOMmTIMMAAAAAAAAAA==\",\n  \"_self\": \"dbs/Ny9FAA==/colls/Ny9FAOMmTIM=/docs/Ny9FAOMmTIMMAAAAAAAAAA==/\",\n  \"_etag\": \"\\\"81004656-0000-2300-0000-66b332a40000\\\"\",\n  \"_attachments\": \"attachments/\",\n  \"_ts\": 1723019940\n}\n</code></pre>"},{"location":"apps/5_streamlit_query_chat_history/","title":"5. Search Chat History","text":"<p>This application is used to search the chat history accumulated in 4_streamlit_chat_history.</p>"},{"location":"apps/5_streamlit_query_chat_history/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.10 or later</li> <li>Azure Cosmos DB</li> </ul>"},{"location":"apps/5_streamlit_query_chat_history/#usage","title":"Usage","text":"<ol> <li>Get the connection string for Azure Cosmos DB</li> <li>Copy .env.template to <code>.env</code> in the same directory</li> <li>Set credentials in <code>.env</code></li> <li>Run main.py</li> </ol> <pre><code># Create a virtual environment\n$ python -m venv .venv\n\n# Activate the virtual environment\n$ source .venv/bin/activate\n\n# Install dependencies\n$ pip install -r requirements.txt\n\n# Run the script\n$ python -m streamlit run apps/5_streamlit_query_chat_history/main.py\n</code></pre>"},{"location":"apps/5_streamlit_query_chat_history/#_1","title":"\u5b9f\u884c\u4f8b","text":"<p>Access <code>http://localhost:8501</code> and set the required fields in the sidebar to search the chat history.</p> <p>When you click the \"Search\" button, the chat history will be displayed.</p> <p></p>"},{"location":"apps/6_call_azure_ai_search/","title":"6. Call Azure AI Search from Python","text":"<p>This application explains how to call Azure AI Search from Python.</p>"},{"location":"apps/6_call_azure_ai_search/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.10 or later</li> <li>Azure AI Search</li> <li>Azure OpenAI Service</li> </ul>"},{"location":"apps/6_call_azure_ai_search/#overview","title":"Overview","text":"<p>Azure AI Search (formerly known as Azure Cognitive Search) is a fully managed cloud search service that provides information retrieval over user-owned content. Data plane REST APIs are used for indexing and query workflows, and are documented in this section. Azure AI Search REST API reference provides detailed information about the APIs.</p> <p>REST API specs in OpenAPI format are available in the Azure/azure-rest-api-specs repository.</p> <p>Samples for Azure Cognitive Search client library for Python are available in the Azure SDK for Python repository.</p> <p>Azure AI Search client library for Python - version 11.5.1 provides primitive APIs for working with Azure AI Search. It is flexible and allows you to work with the service at a lower level.</p> <p>Introducing LangChain</p> <p>LangChain is a framework for developing applications powered by large language models (LLMs). It provides a set of tools and libraries to help you build, train, and deploy LLMs in production.</p> <p></p> <p>On the other hand, for example, the OpenAI Python SDK provides a direct interface to OpenAI's API, enabling developers to integrate OpenAI's powerful language models into their applications</p> <p>The relationship between LangChain and the OpenAI Python SDK is complementary. LangChain leverages the OpenAI Python SDK to access and utilize OpenAI's models, providing a higher-level abstraction that simplifies the integration of these models into more complex workflows and applications.</p> <p>Use LangChain to access Azure AI Search easily</p> <p>Azure AI Search interface in LangChain provides a simple and easy way to access Azure AI Search from Python.</p> <p>Use RecursiveCharacterTextSplitter to recursively split text by characters</p> <p>It is necessary to split text by characters when you need to put text into a search index. Implementing text splitting by characters is a common task in natural language processing (NLP) and information retrieval (IR) applications but it is tedious and error-prone. So we introduce <code>RecursiveCharacterTextSplitter</code> which provides a simple and easy way to recursively split text by characters. Details are available in the following link.</p> <ul> <li>How to recursively split text by characters</li> </ul>"},{"location":"apps/6_call_azure_ai_search/#usage","title":"Usage","text":"<ol> <li>Get the API key for Azure AI Search</li> <li>Copy .env.template to <code>.env</code> in the same directory</li> <li>Set credentials in <code>.env</code></li> <li>Run scripts in the apps/6_call_azure_ai_search directory</li> </ol> <p>[!CAUTION] &gt; <code>AZURE_AI_SEARCH_INDEX_NAME</code> in <code>.env</code> should be unique and should not be changed once set. If you change the index name, you will need to recreate the index and re-upload the documents.</p> <p>Set up the environment and install dependencies:</p> <pre><code># Create a virtual environment\n$ python -m venv .venv\n\n# Activate the virtual environment\n$ source .venv/bin/activate\n\n# Install dependencies\n$ pip install -r requirements.txt\n</code></pre> <p>Create an index in Azure AI Search and upload documents:</p> <p>[!CAUTION] This script should be run only once to avoid creating duplicate indexes.</p> <pre><code>$ INDEX_NAME=yourindexname\n$ FILE=./datasets/yourfile.csv\n$ python apps/6_call_azure_ai_search/1_create_index.py \\\n  --index-name $INDEX_NAME \\\n  --file $FILE \\\n  --verbose\n</code></pre> <p>Search documents in Azure AI Search:</p> <pre><code>$ INDEX_NAME=yourindexname\n$ python apps/6_call_azure_ai_search/2_search_docs.py \\\n  --index-name $INDEX_NAME \\\n  --query \"meeting\" \\\n  --verbose\n\n&gt; All meetings must include a 5-minute meditation session.\n&gt; All meetings must begin with a joke.\n&gt; All meetings must have a theme, such as pirate or superhero.\n</code></pre>"},{"location":"apps/7_streamlit_chat_rag/","title":"7. Add RAG feature to Streamlit chat app","text":"<p>This app demonstrates how to add the Retrieval-Augmented Generation (RAG) feature to a Streamlit chat app.</p>"},{"location":"apps/7_streamlit_chat_rag/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.10 or later</li> <li>Azure OpenAI Service</li> <li>Azure AI Search</li> </ul>"},{"location":"apps/7_streamlit_chat_rag/#overview","title":"Overview","text":"<p>What is RAG?</p> <p>Retrieval-Augmented Generation (RAG) is a model that combines the strengths of retrieval and generation models. It uses a retriever to find relevant passages from a large corpus and then uses a generator to generate a response based on the retrieved passages. In this way, RAG can generate more accurate and informative responses than traditional generation models. This chapter provides an practical example of how to use RAG in a Streamlit chat app with the knowledge that you've learned in the following previous chapters.</p> <ul> <li>LLM: Azure OpenAI Service @ 1_call_azure_openai_chat</li> <li>Chat app: Streamlit @ 2_streamlit_chat</li> <li>Search: Azure AI Search @ 6_call_azure_ai_search</li> </ul> <p>This app just combines the above components to create a chat app with RAG feature.</p> <p>Introducing Function calling</p> <p></p> <p>Function calling is a technical feature that allows you to connect LLM models to external tools and systems. This is useful for many things such as empowering AI assistants with capabilities, or building deep integrations between your applications and the models.</p> <p>For example, if you want to implement chat app with RAG feature, you can use the function calling feature to connect the LLM model to external knowledge bases or search engines. This allows the model to retrieve relevant information from the knowledge base or search engine and generate a response based on that information.</p> <p>Introduce <code>AgentExecutor</code> to introduce function calling</p> <p>Implementing Function Calling from scratch can be complex and time-consuming. To make it easier, LangChain provides a feature called <code>AgentExecutor</code>. AgentExecutor is a feature that allows you to connect LLM models to external tools and systems. This feature enables you to build deep integrations between your applications and the models, and empower AI assistants with capabilities.</p>"},{"location":"apps/7_streamlit_chat_rag/#usage","title":"Usage","text":"<ol> <li>Get Azure OpenAI Service API key</li> <li>Get Azure AI Search API key</li> <li>Copy .env.template to <code>.env</code> in the same directory</li> <li>Set credentials in <code>.env</code></li> <li>Run main.py</li> </ol> <pre><code># Create a virtual environment\n$ python -m venv .venv\n\n# Activate the virtual environment\n$ source .venv/bin/activate\n\n# Install dependencies\n$ pip install -r requirements.txt\n\n# Run the script\n$ python -m streamlit run apps/7_streamlit_chat_rag/main.py\n</code></pre>"},{"location":"apps/7_streamlit_chat_rag/#example","title":"Example","text":"<p>Access <code>http://localhost:8501</code> and set the required fields in the sidebar to start a conversation.</p> <p>When you send a question about Contoso Corporation, the chatbot will respond with an answer from Azure AI Search.</p> <p></p> <p>To see how the RAG feature works, watch the video below.</p> <p></p>"},{"location":"apps/7_streamlit_chat_rag/#how-to-customize","title":"How to customize","text":""},{"location":"apps/7_streamlit_chat_rag/#customize-your-application-purpose","title":"Customize your application purpose","text":"<p>The application purpose is defined in a system prompt. By default, the application provides information about the fictional company Contoso Corporation.</p> <p>To change the behavior of the application, modify the <code>CUSTOM_SYSTEM_PROMPT</code> variable to fit your needs. Also designing prompts, so called \"prompt engineering\", is important to get the best results from the model. There are many resources available to help you design optimal prompts. Here are some recommendations:</p> <ul> <li>Prompt Engineering Guide</li> <li>github.com/dahatake/ChatGPT-Prompt-Sample-Japanese/Workshop_English</li> </ul>"},{"location":"apps/7_streamlit_chat_rag/#customize-tools","title":"Customize tools","text":"<p>As explained in the previous chapter, you can use the function calling feature to connect the LLM model to external tools and systems. To customize the tools, you have only to modify followings.</p> <ol> <li>Implement your own tools just as tools/fetch_contents.py does.</li> <li>Add your tool to the <code>tool</code> array in create_agent() function.</li> </ol>"},{"location":"apps/8_streamlit_azure_openai_batch/","title":"8. Call Azure OpenAI Batch API with Streamlit","text":"<p>This app demonstrates how to call Azure OpenAI Batch API with Streamlit.</p>"},{"location":"apps/8_streamlit_azure_openai_batch/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.10 or later</li> <li>Azure OpenAI Service (Global batch deployment)</li> </ul>"},{"location":"apps/8_streamlit_azure_openai_batch/#usage","title":"Usage","text":"<ol> <li>Get Azure OpenAI Service API key</li> <li>Copy .env.template to <code>.env</code> in the same directory</li> <li>Set credentials in <code>.env</code></li> <li>Run main.py</li> </ol> <pre><code># Create a virtual environment\n$ python -m venv .venv\n\n# Activate the virtual environment\n$ source .venv/bin/activate\n\n# Install dependencies\n$ pip install -r requirements.txt\n\n# Run the script\n$ python -m streamlit run apps/8_streamlit_azure_openai_batch/main.py\n</code></pre>"},{"location":"apps/8_streamlit_azure_openai_batch/#example","title":"Example","text":""},{"location":"apps/8_streamlit_azure_openai_batch/#references","title":"References","text":"<ul> <li>Getting started with Azure OpenAI global batch deployments (preview)</li> </ul>"},{"location":"apps/99_streamlit_examples/","title":"99. Code samples for Streamlit","text":"<p>This app includes code samples for Streamlit. You can run the app and select the sample you want to run from the sidebar.</p>"},{"location":"apps/99_streamlit_examples/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.10 or later</li> <li>Azure OpenAI Service</li> </ul>"},{"location":"apps/99_streamlit_examples/#usage","title":"Usage","text":"<ol> <li>Get Azure OpenAI Service API key</li> <li>Get Azure AI Search API key</li> <li>Copy .env.template to <code>.env</code> in the same directory</li> <li>Set credentials in <code>.env</code></li> <li>Run main.py</li> </ol> <pre><code># Create a virtual environment\n$ python -m venv .venv\n\n# Activate the virtual environment\n$ source .venv/bin/activate\n\n# Install dependencies\n$ pip install -r requirements.txt\n\n# Run the script\n$ python -m streamlit run apps/99_streamlit_examples/main.py\n</code></pre>"},{"location":"apps/99_streamlit_examples/#example","title":"Example","text":"<p>Access to http://localhost:8501 and select the sample you want to run from the sidebar.</p>"},{"location":"apps/99_streamlit_examples/#1-file-qa","title":"1. File Q&amp;A","text":""},{"location":"apps/99_streamlit_examples/#2-image-qa","title":"2. Image Q&amp;A","text":""},{"location":"apps/99_streamlit_examples/#3-camera-qa","title":"3. Camera Q&amp;A","text":""},{"location":"apps/99_streamlit_examples/#4-translate-text","title":"4. Translate text","text":""},{"location":"apps/99_streamlit_examples/#5-explain-data","title":"5. Explain data","text":""},{"location":"apps/99_streamlit_examples/#6-speech-to-text","title":"6. Speech to Text","text":""},{"location":"apps/99_streamlit_examples/#7-text-to-speech","title":"7. Text to Speech","text":""},{"location":"apps/99_streamlit_examples/#8-create-image","title":"8. Create image","text":""},{"location":"apps/99_streamlit_examples/#9-visualize-location","title":"9. Visualize location","text":""},{"location":"apps/99_streamlit_examples/#10-object-detection","title":"10. Object detection","text":""},{"location":"apps/99_streamlit_examples/#11-pose-estimation","title":"11. Pose estimation","text":""},{"location":"apps/99_streamlit_examples/#12-video-processing","title":"12. Video processing","text":"<p>ref. data-videos/traffic.mp4</p>"},{"location":"apps/99_streamlit_examples/#references","title":"References","text":"<ul> <li>\ud83c\udf88 Streamlit + LLM Examples App</li> <li>Streamlit &gt; st.plotly_chart</li> <li>Plotly &gt; Time Series and Date Axes in Python</li> </ul>"},{"location":"apps/9_streamlit_azure_document_intelligence/","title":"9. Call Azure Document Intelligence API with Streamlit","text":"<p>This Streamlit app demonstrates how to call Azure Document Intelligence API with Streamlit.</p>"},{"location":"apps/9_streamlit_azure_document_intelligence/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.10 or later</li> <li>Azure Document Intelligence API key</li> </ul>"},{"location":"apps/9_streamlit_azure_document_intelligence/#usage","title":"Usage","text":"<ol> <li>Get Azure Document Intelligence API key</li> <li>Copy .env.template to <code>.env</code> in the same directory</li> <li>Set credentials in <code>.env</code></li> <li>Run main.py</li> </ol> <pre><code># Create a virtual environment\n$ python -m venv .venv\n\n# Activate the virtual environment\n$ source .venv/bin/activate\n\n# Install dependencies\n$ pip install -r requirements.txt\n\n# Run the script\n$ python -m streamlit run apps/9_streamlit_azure_document_intelligence/main.py\n</code></pre>"},{"location":"apps/9_streamlit_azure_document_intelligence/#example","title":"Example","text":""},{"location":"apps/9_streamlit_azure_document_intelligence/#references","title":"References","text":"<ul> <li>Azure AI Document Intelligence client library for Python - version 1.0.0b3</li> </ul>"}]}